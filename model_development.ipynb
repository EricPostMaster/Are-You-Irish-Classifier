{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vTqd_a5YgMTVUGfc6F9dx62fvq2ptPvyq6cGpfAtPMYWTDn1qiVg2_ma79xS2NyQ-CHkOXy_MzCd03I/pub?gid=712009217&single=true&output=csv')\n",
    "# Note: The encoding is not removing spaces, apostrophes, or accents on characters\n",
    "# I manually removed them for now. #TechDebt\n",
    "\n",
    "\n",
    "# Import other countries\n",
    "country_urls = ['https://docs.google.com/spreadsheets/d/e/2PACX-1vTqd_a5YgMTVUGfc6F9dx62fvq2ptPvyq6cGpfAtPMYWTDn1qiVg2_ma79xS2NyQ-CHkOXy_MzCd03I/pub?gid=1621398561&single=true&output=csv'\n",
    "               ,'https://docs.google.com/spreadsheets/d/e/2PACX-1vTqd_a5YgMTVUGfc6F9dx62fvq2ptPvyq6cGpfAtPMYWTDn1qiVg2_ma79xS2NyQ-CHkOXy_MzCd03I/pub?gid=1688323099&single=true&output=csv'\n",
    "               ,'https://docs.google.com/spreadsheets/d/e/2PACX-1vTqd_a5YgMTVUGfc6F9dx62fvq2ptPvyq6cGpfAtPMYWTDn1qiVg2_ma79xS2NyQ-CHkOXy_MzCd03I/pub?gid=311250649&single=true&output=csv' \n",
    "               ]\n",
    "\n",
    "big_surname_list = []\n",
    "\n",
    "# Multiply each name by the number of times it should be in the list (col index 5)\n",
    "for url in country_urls:\n",
    "    country_df = pd.read_csv(url, usecols=[1,5])\n",
    "    country_surnames = country_df.values.tolist()\n",
    "\n",
    "    for name in country_surnames:\n",
    "        for qty in range(0,name[1]):\n",
    "            big_surname_list.append(name[0])\n",
    "\n",
    "# Create 0 flags for all new names\n",
    "surname_flags = [0] * len(big_surname_list)\n",
    "\n",
    "# Zip it all together and join into master dataframe\n",
    "new_surnames = pd.DataFrame(list(zip(big_surname_list,surname_flags)), columns=['surname_plain','irish_flag'])\n",
    "df = pd.concat([df, new_surnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best model parameters: {'clf__alpha': 0.1, 'vec__analyzer': 'char_wb', 'vec__ngram_range': (5, 5)}\n",
      "\n",
      "Best training F2 score: 0.8693676972849392\n",
      "\n",
      "F2 score on test data: 0.8968347010550997\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1536\n",
      "           1       0.80      0.92      0.86       497\n",
      "\n",
      "    accuracy                           0.93      2033\n",
      "   macro avg       0.89      0.93      0.90      2033\n",
      "weighted avg       0.93      0.93      0.93      2033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['surname_plain'], df['irish_flag'], test_size=0.15, random_state=123, stratify=df['irish_flag'])\n",
    "\n",
    "pipe = Pipeline([('vec', CountVectorizer())\n",
    "                ,('clf', ComplementNB())\n",
    "                # ,('rf', RandomForestClassifier())\n",
    "                # ,('knn', KNeighborsClassifier())\n",
    "                ])\n",
    "param_grid = [{'vec__ngram_range':[(3,3),(4,4),(5,5)]\n",
    "              ,'vec__analyzer':['char','char_wb']\n",
    "              ,'clf__alpha':[0.01, 0.1, 0.5, 1, 10]\n",
    "              # ,'knn__n_neighbors':[1,2,3,4,5]\n",
    "              # ,'knn__weights':['uniform','distance']\n",
    "              }]\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "\n",
    "gs = GridSearchCV(pipe\n",
    "                  ,param_grid=param_grid\n",
    "                  ,cv=3\n",
    "                  ,verbose=1\n",
    "                  ,scoring=f2_scorer)\n",
    "gs.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Best model parameters: {gs.best_params_}\")\n",
    "final_model_params = gs.best_params_\n",
    "print()\n",
    "print(f\"Best training F2 score: {gs.best_score_}\")\n",
    "print()\n",
    "# print(gs.cv_results_['mean_test_score'],'\\n',gs.cv_results_['std_test_score'])\n",
    "\n",
    "df_pred = pd.DataFrame(zip(X_test,y_test,gs.predict_proba(X_test),gs.predict(X_test), gs.predict_log_proba(X_test)))\n",
    "\n",
    "print(f\"F2 score on test data: {gs.score(X_test, y_test)}\")\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, gs.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipe = Pipeline([('vec', CountVectorizer(analyzer='char_wb', ngram_range=(4,4)))\n",
    "                      ,('clf', ComplementNB(alpha=1))\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = final_pipe.fit(df['surname_plain'], df['irish_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4083782189053284"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the correct prior probability of an Irish name\n",
    "final_model['clf'].class_log_prior_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.02232262, -10.12093491, -10.12093491, ..., -10.12093491,\n",
       "       -10.12093491, -10.12093491])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the correct feature log probabilities of a feature in the Irish name class\n",
    "final_model['clf'].feature_log_prob_[0]*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salient_words(nb_clf, vect, class_ind):\n",
    "    \"\"\"Return salient words for given class\n",
    "    Parameters\n",
    "    ----------\n",
    "    nb_clf : a Naive Bayes classifier (e.g. MultinomialNB, BernoulliNB)\n",
    "    vect : CountVectorizer\n",
    "    class_ind : int\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        a sorted list of (word, log prob) sorted by log probability in descending order.\n",
    "\n",
    "    Note: Feature log probabilities for Class 1 are obtained by calling all the feature log probabilities for Class 0 and  multiplying them by -1\n",
    "    \"\"\"\n",
    "\n",
    "    words = vect.get_feature_names()\n",
    "    zipped = list(zip(words, nb_clf.feature_log_prob_[class_ind]*-1))\n",
    "    sorted_zip = sorted(zipped, key=lambda t: t[1], reverse=True)\n",
    "\n",
    "    return sorted_zip\n",
    "\n",
    "pos_all = get_salient_words(final_model['clf'], final_model['vec'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.120934911305456\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(list(filter(lambda prob: prob[0] == 'kwu ', pos_all))[0][1])\n",
    "except:\n",
    "    print('nope')\n",
    "# Murphy score is -39.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saved-objects/irish_log_probs.p\", \"wb\") as p:\n",
    "    pickle.dump(pos_all, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(neg_salient_top_20)\n",
    "df_features = pd.DataFrame(pos_all, columns=['ngram','log_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.120854    4939\n",
       "-9.427707      789\n",
       "-9.022242      242\n",
       "-8.734560      186\n",
       "-8.511417      157\n",
       "              ... \n",
       "-5.946467        1\n",
       "-6.009981        1\n",
       "-6.208831        1\n",
       "-6.249653        1\n",
       "-6.131870        1\n",
       "Name: log_prob, Length: 68, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features['log_prob'].value_counts()\n",
    "# 910 log_prob values that aren't the last category\n",
    "# 3697 values that are the last category\n",
    "# 4607 total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Murphy\n",
      "[[' mur' -5.751406598605862]]\n",
      "[['murp' -6.788649940897679]]\n",
      "[['urph' -6.788649940897679]]\n",
      "[['rphy' -6.788649940897679]]\n",
      "[['phy ' -6.6551185482731565]]\n",
      "Sims\n",
      "[[' sim' -10.120854451072884]]\n",
      "[['sims' -10.120854451072884]]\n",
      "[['ims ' -10.120854451072884]]\n"
     ]
    }
   ],
   "source": [
    "df_features.head(10)\n",
    "print('Murphy')\n",
    "print(df_features[df_features['ngram']==' mur'].values)\n",
    "print(df_features[df_features['ngram']=='murp'].values)\n",
    "print(df_features[df_features['ngram']=='urph'].values)\n",
    "print(df_features[df_features['ngram']=='rphy'].values)\n",
    "print(df_features[df_features['ngram']=='phy '].values)\n",
    "# Murphy prob = 0.000000000000005 (that's 14 zeros)\n",
    "# 5.0e-15\n",
    "# Murphy index ~6.58\n",
    "\n",
    "# print('Bailey')\n",
    "# print(df_features[df_features['ngram']==' bai'].values)\n",
    "# print(df_features[df_features['ngram']=='bail'].values)\n",
    "# print(df_features[df_features['ngram']=='aile'].values)\n",
    "# print(df_features[df_features['ngram']=='iley'].values)\n",
    "# print(df_features[df_features['ngram']=='ley '].values)\n",
    "# Bailey prob = 0.000000000000000014 (that's 16 zeros)\n",
    "# 1.4e-17\n",
    "# Bailey 7.762\n",
    "# Murphy index = 6.58/7.762 = .8477\n",
    "\n",
    "# print('Burkson')\n",
    "# print(df_features[df_features['ngram']==' bur'].values)\n",
    "# print(df_features[df_features['ngram']=='burk'].values)\n",
    "# print(df_features[df_features['ngram']=='urks'].values)\n",
    "# print(df_features[df_features['ngram']=='rkso'].values)\n",
    "# print(df_features[df_features['ngram']=='kson'].values)\n",
    "# print(df_features[df_features['ngram']=='son '].values)\n",
    "# Burkson 8.18\n",
    "# Murphy index = 6.58/8.18 = .8044\n",
    "\n",
    "print('Sims')\n",
    "print(df_features[df_features['ngram']==' sim'].values)\n",
    "print(df_features[df_features['ngram']=='sims'].values)\n",
    "print(df_features[df_features['ngram']=='ims '].values)\n",
    "# Sims 8.68\n",
    "# Murphy index = 6.58/8.68 = .7581\n",
    "\n",
    "# print('Ravichandran')\n",
    "# print(df_features[df_features['ngram']==' rav'].values)\n",
    "# print(df_features[df_features['ngram']=='ravi'].values)\n",
    "# print(df_features[df_features['ngram']=='avic'].values)\n",
    "# print(df_features[df_features['ngram']=='vich'].values)\n",
    "# print(df_features[df_features['ngram']=='icha'].values)\n",
    "# print(df_features[df_features['ngram']=='chan'].values)\n",
    "# print(df_features[df_features['ngram']=='hand'].values)\n",
    "# print(df_features[df_features['ngram']=='andr'].values)\n",
    "# print(df_features[df_features['ngram']=='ndra'].values)\n",
    "# print(df_features[df_features['ngram']=='dran'].values)\n",
    "# print(df_features[df_features['ngram']=='ran '].values)\n",
    "# Ravichandran 8.38\n",
    "# Murphy index = 6.58/8.38 = .7852\n",
    "\n",
    "\n",
    "# print('Platzfelder')\n",
    "# print(df_features[df_features['ngram']==' pla'].values)\n",
    "# print(df_features[df_features['ngram']=='plat'].values)\n",
    "# print(df_features[df_features['ngram']=='latz'].values)\n",
    "# print(df_features[df_features['ngram']=='atzf'].values)\n",
    "# print(df_features[df_features['ngram']=='tzfe'].values)\n",
    "# print(df_features[df_features['ngram']=='zfel'].values)\n",
    "# print(df_features[df_features['ngram']=='feld'].values)\n",
    "# print(df_features[df_features['ngram']=='elde'].values)\n",
    "# print(df_features[df_features['ngram']=='lder'].values)\n",
    "# print(df_features[df_features['ngram']=='der '].values)\n",
    "\n",
    "# print('Timothy')\n",
    "# print(df_features[df_features['ngram']==' tim'].values)\n",
    "# print(df_features[df_features['ngram']=='timo'].values)\n",
    "# print(df_features[df_features['ngram']=='imot'].values)\n",
    "# print(df_features[df_features['ngram']=='moth'].values)\n",
    "# print(df_features[df_features['ngram']=='othy'].values)\n",
    "# print(df_features[df_features['ngram']=='thy '].values)\n",
    "# Timothy 8.33\n",
    "# Murphy index 6.58/8.33 = .7899\n",
    "\n",
    "# Murphy index could be Avg log probability of a name divided by the avg log probability of the name Murphy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>log_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mur</td>\n",
       "      <td>-6.485653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ngram  log_prob\n",
       "0   mur -6.485653"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features[df_features['ngram']==' mur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>log_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>larn</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>las</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>ledd</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>ling</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>lloc</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>low</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>lyhu</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>ment</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>mick</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>morg</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>ngto</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>nin</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>nis</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>nley</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>nnis</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>ocon</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>off</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>ophy</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>ore</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>orga</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>ormi</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>osbi</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>ougl</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>rana</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>ratc</td>\n",
       "      <td>-8.329095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ngram  log_prob\n",
       "925  larn -8.329095\n",
       "926  las  -8.329095\n",
       "927  ledd -8.329095\n",
       "928  ling -8.329095\n",
       "929  lloc -8.329095\n",
       "930  low  -8.329095\n",
       "931  lyhu -8.329095\n",
       "932  ment -8.329095\n",
       "933  mick -8.329095\n",
       "934  morg -8.329095\n",
       "935  ngto -8.329095\n",
       "936  nin  -8.329095\n",
       "937  nis  -8.329095\n",
       "938  nley -8.329095\n",
       "939  nnis -8.329095\n",
       "940  ocon -8.329095\n",
       "941  off  -8.329095\n",
       "942  ophy -8.329095\n",
       "943  ore  -8.329095\n",
       "944  orga -8.329095\n",
       "945  ormi -8.329095\n",
       "946  osbi -8.329095\n",
       "947  ougl -8.329095\n",
       "948  rana -8.329095\n",
       "949  ratc -8.329095"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features[925:950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickled_CompNB_model.p\", \"wb\") as p:\n",
    "    pickle.dump(final_model, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00583429, -5.14691913]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.predict_log_proba(['Knickerbocker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60195858, 0.39804142]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.predict_proba(['Sims'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now I have a model. Now I need to put it in a Streamlit app that can receive input from the user and return a response of some sort."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6524d49d688450fc3d47611e48c8230f50bdaae02d55d1a5f70db79bfcaf4363"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
