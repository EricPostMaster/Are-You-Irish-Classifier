{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Are You Irish\" model development notebook\n",
    "\n",
    "TL;DR:\n",
    "The model is a Complement Naive Bayes, and the grid search selection criteria was F2 because I wanted to err on the side of Recall and minimizing False Negatives, even at the cost of False Positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build dataset from CSV files in Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vTqd_a5YgMTVUGfc6F9dx62fvq2ptPvyq6cGpfAtPMYWTDn1qiVg2_ma79xS2NyQ-CHkOXy_MzCd03I/pub?gid=712009217&single=true&output=csv')\n",
    "# Note: The encoding is not removing spaces, apostrophes, or accents on characters\n",
    "# I manually removed them for now. #TechDebt\n",
    "\n",
    "\n",
    "# Import other countries\n",
    "country_urls = ['https://docs.google.com/spreadsheets/d/e/2PACX-1vTqd_a5YgMTVUGfc6F9dx62fvq2ptPvyq6cGpfAtPMYWTDn1qiVg2_ma79xS2NyQ-CHkOXy_MzCd03I/pub?gid=1621398561&single=true&output=csv'\n",
    "               ,'https://docs.google.com/spreadsheets/d/e/2PACX-1vTqd_a5YgMTVUGfc6F9dx62fvq2ptPvyq6cGpfAtPMYWTDn1qiVg2_ma79xS2NyQ-CHkOXy_MzCd03I/pub?gid=1688323099&single=true&output=csv'\n",
    "               ,'https://docs.google.com/spreadsheets/d/e/2PACX-1vTqd_a5YgMTVUGfc6F9dx62fvq2ptPvyq6cGpfAtPMYWTDn1qiVg2_ma79xS2NyQ-CHkOXy_MzCd03I/pub?gid=311250649&single=true&output=csv' \n",
    "               ]\n",
    "\n",
    "big_surname_list = []\n",
    "\n",
    "# Multiply each name by the number of times it should be in the list (col index 5)\n",
    "for url in country_urls:\n",
    "    country_df = pd.read_csv(url, usecols=[1,5])\n",
    "    country_surnames = country_df.values.tolist()\n",
    "\n",
    "    for name in country_surnames:\n",
    "        for qty in range(0,name[1]):\n",
    "            big_surname_list.append(name[0])\n",
    "\n",
    "# Create 0 flags for all new names\n",
    "surname_flags = [0] * len(big_surname_list)\n",
    "\n",
    "# Zip it all together and join into master dataframe\n",
    "new_surnames = pd.DataFrame(list(zip(big_surname_list,surname_flags)), columns=['surname_plain','irish_flag'])\n",
    "df = pd.concat([df, new_surnames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search based on F2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best model parameters: {'clf__alpha': 0.1, 'vec__analyzer': 'char_wb', 'vec__ngram_range': (5, 5)}\n",
      "\n",
      "Best training F2 score: 0.8693676972849392\n",
      "\n",
      "F2 score on test data: 0.8968347010550997\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1536\n",
      "           1       0.80      0.92      0.86       497\n",
      "\n",
      "    accuracy                           0.93      2033\n",
      "   macro avg       0.89      0.93      0.90      2033\n",
      "weighted avg       0.93      0.93      0.93      2033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['surname_plain'], df['irish_flag'], test_size=0.15, random_state=123, stratify=df['irish_flag'])\n",
    "\n",
    "pipe = Pipeline([('vec', CountVectorizer())\n",
    "                ,('clf', ComplementNB())\n",
    "                # ,('rf', RandomForestClassifier())\n",
    "                # ,('knn', KNeighborsClassifier())\n",
    "                ])\n",
    "param_grid = [{'vec__ngram_range':[(3,3),(4,4),(5,5)]\n",
    "              ,'vec__analyzer':['char','char_wb']\n",
    "              ,'clf__alpha':[0.01, 0.1, 0.5, 1, 10]\n",
    "              # ,'knn__n_neighbors':[1,2,3,4,5]\n",
    "              # ,'knn__weights':['uniform','distance']\n",
    "              }]\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "\n",
    "gs = GridSearchCV(pipe\n",
    "                  ,param_grid=param_grid\n",
    "                  ,cv=3\n",
    "                  ,verbose=1\n",
    "                  ,scoring=f2_scorer)\n",
    "gs.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Best model parameters: {gs.best_params_}\")\n",
    "final_model_params = gs.best_params_\n",
    "print()\n",
    "print(f\"Best training F2 score: {gs.best_score_}\")\n",
    "print()\n",
    "# print(gs.cv_results_['mean_test_score'],'\\n',gs.cv_results_['std_test_score'])\n",
    "\n",
    "df_pred = pd.DataFrame(zip(X_test,y_test,gs.predict_proba(X_test),gs.predict(X_test), gs.predict_log_proba(X_test)))\n",
    "\n",
    "print(f\"F2 score on test data: {gs.score(X_test, y_test)}\")\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, gs.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create final pipeline with tuned hyperparameters, train final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipe = Pipeline([('vec', CountVectorizer(analyzer='char_wb', ngram_range=(4,4)))\n",
    "                      ,('clf', ComplementNB(alpha=0.1))\n",
    "                      ])\n",
    "                      \n",
    "final_model = final_pipe.fit(df['surname_plain'], df['irish_flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get class `irish_flag=1` feature log probabilities, save for use in app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salient_words(nb_clf, vect, class_ind):\n",
    "    \"\"\"Return salient words for given class\n",
    "    Parameters\n",
    "    ----------\n",
    "    nb_clf : a Naive Bayes classifier (e.g. MultinomialNB, BernoulliNB)\n",
    "    vect : CountVectorizer\n",
    "    class_ind : int\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        a sorted list of (word, log prob) sorted by log probability in descending order.\n",
    "\n",
    "    Note: Feature log probabilities for Class 1 are obtained by calling all the feature log probabilities for Class 0 and  multiplying them by -1\n",
    "    \"\"\"\n",
    "\n",
    "    words = vect.get_feature_names()\n",
    "    zipped = list(zip(words, nb_clf.feature_log_prob_[class_ind]*-1))\n",
    "    sorted_zip = sorted(zipped, key=lambda t: t[1], reverse=True)\n",
    "\n",
    "    return sorted_zip\n",
    "\n",
    "pos_all = get_salient_words(final_model['clf'], final_model['vec'], 0)\n",
    "\n",
    "#Pickle for use in app\n",
    "with open(\"saved-objects/irish_log_probs.p\", \"wb\") as p:\n",
    "    pickle.dump(pos_all, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7289 different ngrams.\n",
      "There are 82 different probability values.\n",
      "\n",
      "Minimum feature log probability: -12.117126671140499\n",
      "Maximum feature log probability: -4.695949142545048\n",
      "\n",
      "Occurrences of each probability value:\n",
      "-12.117127    3353\n",
      "-12.117127    1247\n",
      "-9.719231      784\n",
      "-12.117127     273\n",
      "-9.072604      237\n",
      "              ... \n",
      "-5.443829        1\n",
      "-7.099847        1\n",
      "-4.695949        1\n",
      "-5.495721        1\n",
      "-5.842365        1\n",
      "Name: log_prob, Length: 82, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each ngram combination, probabilities\n",
    "df_features = pd.DataFrame(pos_all, columns=['ngram','log_prob'])\n",
    "print(f\"There are {df_features['ngram'].nunique()} different ngrams.\")\n",
    "print(f\"There are {len(df_features['log_prob'].value_counts())} different probability values.\")\n",
    "print()\n",
    "\n",
    "# Max and min log probabilities\n",
    "print(f\"Minimum feature log probability: {df_features['log_prob'].min()}\")\n",
    "print(f\"Maximum feature log probability: {df_features['log_prob'].max()}\")\n",
    "print()\n",
    "\n",
    "# View counts of log probability values\n",
    "print(\"Occurrences of each probability value:\")\n",
    "print(df_features['log_prob'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for later\n",
    "with open(\"saved-objects/pickled_CompNB_model.p\", \"wb\") as p:\n",
    "    pickle.dump(final_model, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Extra Stuff) Score Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4083782189053284"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the class prior log probability of an Irish name\n",
    "final_model['clf'].class_log_prior_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.07260423, -12.11712667, -12.11712667, ..., -12.11712667,\n",
       "       -12.11712667, -12.11712667])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the correct feature log probabilities of a feature in the Irish name class\n",
    "final_model['clf'].feature_log_prob_[0]*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Murphy\n",
      "[[' mur' -5.4565515213007565]]\n",
      "[['murp' -6.515007850260742]]\n",
      "[['urph' -6.515007850260742]]\n",
      "[['rphy' -6.515007850260742]]\n",
      "[['phy ' -6.377333758961208]]\n",
      "Sims\n",
      "[[' sim' -12.117126671140428]]\n",
      "[['sims' -12.117126671140445]]\n",
      "[['ims ' -12.117126671140445]]\n"
     ]
    }
   ],
   "source": [
    "df_features.head(10)\n",
    "print('Murphy')\n",
    "print(df_features[df_features['ngram']==' mur'].values)\n",
    "print(df_features[df_features['ngram']=='murp'].values)\n",
    "print(df_features[df_features['ngram']=='urph'].values)\n",
    "print(df_features[df_features['ngram']=='rphy'].values)\n",
    "print(df_features[df_features['ngram']=='phy '].values)\n",
    "# Murphy prob = 0.000000000000005 (that's 14 zeros)\n",
    "# 5.0e-15\n",
    "# Murphy index ~6.58\n",
    "\n",
    "# print('Bailey')\n",
    "# print(df_features[df_features['ngram']==' bai'].values)\n",
    "# print(df_features[df_features['ngram']=='bail'].values)\n",
    "# print(df_features[df_features['ngram']=='aile'].values)\n",
    "# print(df_features[df_features['ngram']=='iley'].values)\n",
    "# print(df_features[df_features['ngram']=='ley '].values)\n",
    "# Bailey prob = 0.000000000000000014 (that's 16 zeros)\n",
    "# 1.4e-17\n",
    "# Bailey 7.762\n",
    "# Murphy index = 6.58/7.762 = .8477\n",
    "\n",
    "# print('Burkson')\n",
    "# print(df_features[df_features['ngram']==' bur'].values)\n",
    "# print(df_features[df_features['ngram']=='burk'].values)\n",
    "# print(df_features[df_features['ngram']=='urks'].values)\n",
    "# print(df_features[df_features['ngram']=='rkso'].values)\n",
    "# print(df_features[df_features['ngram']=='kson'].values)\n",
    "# print(df_features[df_features['ngram']=='son '].values)\n",
    "# Burkson 8.18\n",
    "# Murphy index = 6.58/8.18 = .8044\n",
    "\n",
    "print('Sims')\n",
    "print(df_features[df_features['ngram']==' sim'].values)\n",
    "print(df_features[df_features['ngram']=='sims'].values)\n",
    "print(df_features[df_features['ngram']=='ims '].values)\n",
    "# Sims 8.68\n",
    "# Murphy index = 6.58/8.68 = .7581\n",
    "\n",
    "# print('Ravichandran')\n",
    "# print(df_features[df_features['ngram']==' rav'].values)\n",
    "# print(df_features[df_features['ngram']=='ravi'].values)\n",
    "# print(df_features[df_features['ngram']=='avic'].values)\n",
    "# print(df_features[df_features['ngram']=='vich'].values)\n",
    "# print(df_features[df_features['ngram']=='icha'].values)\n",
    "# print(df_features[df_features['ngram']=='chan'].values)\n",
    "# print(df_features[df_features['ngram']=='hand'].values)\n",
    "# print(df_features[df_features['ngram']=='andr'].values)\n",
    "# print(df_features[df_features['ngram']=='ndra'].values)\n",
    "# print(df_features[df_features['ngram']=='dran'].values)\n",
    "# print(df_features[df_features['ngram']=='ran '].values)\n",
    "# Ravichandran 8.38\n",
    "# Murphy index = 6.58/8.38 = .7852\n",
    "\n",
    "\n",
    "# print('Platzfelder')\n",
    "# print(df_features[df_features['ngram']==' pla'].values)\n",
    "# print(df_features[df_features['ngram']=='plat'].values)\n",
    "# print(df_features[df_features['ngram']=='latz'].values)\n",
    "# print(df_features[df_features['ngram']=='atzf'].values)\n",
    "# print(df_features[df_features['ngram']=='tzfe'].values)\n",
    "# print(df_features[df_features['ngram']=='zfel'].values)\n",
    "# print(df_features[df_features['ngram']=='feld'].values)\n",
    "# print(df_features[df_features['ngram']=='elde'].values)\n",
    "# print(df_features[df_features['ngram']=='lder'].values)\n",
    "# print(df_features[df_features['ngram']=='der '].values)\n",
    "\n",
    "# print('Timothy')\n",
    "# print(df_features[df_features['ngram']==' tim'].values)\n",
    "# print(df_features[df_features['ngram']=='timo'].values)\n",
    "# print(df_features[df_features['ngram']=='imot'].values)\n",
    "# print(df_features[df_features['ngram']=='moth'].values)\n",
    "# print(df_features[df_features['ngram']=='othy'].values)\n",
    "# print(df_features[df_features['ngram']=='thy '].values)\n",
    "# Timothy 8.33\n",
    "# Murphy index 6.58/8.33 = .7899\n",
    "\n",
    "# Murphy index could be Avg log probability of a name divided by the avg log probability of the name Murphy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.84612043e-03, -6.29559182e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.predict_log_proba(['Knickerbocker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99966688e-01, 3.33115689e-05]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.predict_proba(['Sims'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6524d49d688450fc3d47611e48c8230f50bdaae02d55d1a5f70db79bfcaf4363"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
