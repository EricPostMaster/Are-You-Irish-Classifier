{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "# from ngram_config import ngram_creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('irish_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(CountVectorizer(),MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in 3-5:\n",
    "    get ngrams of length n\n",
    "    stratify the data\n",
    "        train the model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_test, predicted_labels, predicted_probs, fold_no):\n",
    "    \"\"\"\n",
    "    Docstring here\n",
    "    \n",
    "    Input: \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # I'm using the F2 score because I want to maximize recall (minimize false negatives)\n",
    "    # I say that because I want to capture as many Irish names as possible,\n",
    "    # even if that means saying that others' names are more Irish than they really are.\n",
    "\n",
    "    # f1 = f1_score(y_test, predicted_labels)\n",
    "    f2 = fbeta_score(y_test, predicted_labels, average='binary', beta=2)\n",
    "\n",
    "    cmatrix = confusion_matrix(y_test, predicted_labels)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predicted_labels).ravel()\n",
    "\n",
    "    FNR = fn/(fn+tp)\n",
    "\n",
    "    pred_prob_results = pd.DataFrame(predicted_probs, columns=['irish_prob', 'not_irish_prob'])\n",
    "    # pred_prob_results['test_index'] = test_index\n",
    "\n",
    "    fold_summary = {'fold_no':fold_no\n",
    "                    # ,'f1_score':f1\n",
    "                    ,'f2_score':f2\n",
    "                    ,'confusion_matrix':{'tn':tn, 'fp':fp, 'fn':fn, 'tp':tp}\n",
    "                    ,'predicted_probabilities':pred_prob_results\n",
    "                    }\n",
    "\n",
    "    return fold_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train, test, fold_no, X=['ngrams'], y=['irish_flag'], n=n):\n",
    "\n",
    "    \"\"\"\n",
    "    Docstring here\n",
    "    \"\"\"\n",
    "\n",
    "    fold_summaries = {}\n",
    "\n",
    "    X_train = train['ngrams'] #.values\n",
    "    y_train = train['irish_flag']\n",
    "\n",
    "    X_test = test['ngrams'].values\n",
    "    y_test = test['irish_flag']\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted_labels = model.predict(X_test)\n",
    "    predicted_probs = model.predict_proba(X_test)  # Return predicted probabilities for X_test data\n",
    "\n",
    "    y_score = model.predict_proba(X_test)[:,1]  # What does this do?\n",
    "\n",
    "    # Evaluate Models, Output Model Summary\n",
    "    fold_summary = evaluate_model(y_test, predicted_labels, predicted_probs, fold_no=fold_no)\n",
    "\n",
    "    # Aggregate Model Summaries\n",
    "    fold_summaries[f'ngrams_{n}'] = fold_summary\n",
    "\n",
    "    return fold_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_model(df, target, model_type):\n",
    "    \"\"\"\n",
    "    This function trains a model on each of the stratified folds and returns\n",
    "    a summary of the results.\n",
    "\n",
    "    Input:\n",
    "        df: (dataframe) Data to be used. Should have a column of ngrams and a target column\n",
    "        target: (series) Target column of input df\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    model_summary_dict = {}\n",
    "    fold_no = 1\n",
    "\n",
    "    for train_index, test_index in skf.split(df, target):\n",
    "        train = df.loc[train_index,:]\n",
    "        test = df.loc[test_index,:]\n",
    "        model_summary = train_model(train, test, X=['ngrams'], y=['irish_flag'], n=n, fold_no=fold_no)\n",
    "        model_summary_dict[f\"fold_{fold_no}\"] = model_summary\n",
    "        fold_no += 1\n",
    "    \n",
    "    return model_summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_creator(term_list, n=3):\n",
    "    \"\"\"\n",
    "    Takes two arguments: a list of words to break into ngrams and the length of the ngram\n",
    "\n",
    "    Inputs:\n",
    "        term_list: [list] terms to break into intraword ngrams (example: df['names'])\n",
    "        n: [int] desired length of ngrams\n",
    "    \n",
    "    Outputs:\n",
    "        ngrams of individual words: e.g., bigrams for 'dog' = ['do','og']\n",
    "        gram_string_list: list where each element is the set of n-grams for each original record. Use in CountVectorizer\n",
    "    \"\"\"\n",
    "\n",
    "    gram_string_list = []\n",
    "    gram_length = n\n",
    "\n",
    "    for i in term_list:\n",
    "        i = str(i)\n",
    "        i = re.sub('[^A-Za-z0-9]+', '', i) # Remove any punctuation, spaces, and special characters\n",
    "        i = i.lower()\n",
    "        i = \"^\"+i+\"$\"  # Add initial and terminal clusters\n",
    "        word_grams = []\n",
    "        gram_string = \"\"\n",
    "        for j in range(gram_length,100):\n",
    "            gram = i[j-gram_length:j]\n",
    "            if len(gram) == gram_length:  # only keep ngrams of the correct length\n",
    "                word_grams.append(gram)\n",
    "                gram_string = gram_string + gram + \" \"\n",
    "        gram_string = gram_string[:-1]  # Cut that last space off the end there\n",
    "        gram_string_list.append(gram_string)  # Append the ngrams for the current name as a space-separated string\n",
    "    \n",
    "    return gram_string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ngrams_3': {'fold_no': 1, 'f2_score': 0.32019704433497537, 'confusion_matrix': {'tn': 235, 'fp': 14, 'fn': 31, 'tp': 13}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.998145        0.001855\n",
      "1      0.674257        0.325743\n",
      "2      0.013198        0.986802\n",
      "3      0.991864        0.008136\n",
      "4      0.990488        0.009512\n",
      "..          ...             ...\n",
      "288    0.994184        0.005816\n",
      "289    0.999301        0.000699\n",
      "290    0.994734        0.005266\n",
      "291    0.999014        0.000986\n",
      "292    0.999971        0.000029\n",
      "\n",
      "[293 rows x 2 columns]}}\n",
      "{'ngrams_3': {'fold_no': 2, 'f2_score': 0.24154589371980673, 'confusion_matrix': {'tn': 227, 'fp': 21, 'fn': 34, 'tp': 10}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.997052    2.948185e-03\n",
      "1      0.206652    7.933485e-01\n",
      "2      0.201359    7.986407e-01\n",
      "3      0.999995    4.929512e-06\n",
      "4      0.993146    6.853827e-03\n",
      "..          ...             ...\n",
      "287    0.004269    9.957306e-01\n",
      "288    0.984464    1.553611e-02\n",
      "289    0.801598    1.984021e-01\n",
      "290    0.999999    9.622692e-07\n",
      "291    0.999615    3.850413e-04\n",
      "\n",
      "[292 rows x 2 columns]}}\n",
      "{'ngrams_3': {'fold_no': 3, 'f2_score': 0.297029702970297, 'confusion_matrix': {'tn': 231, 'fp': 18, 'fn': 31, 'tp': 12}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.997544    2.456087e-03\n",
      "1      0.980035    1.996490e-02\n",
      "2      0.998687    1.312848e-03\n",
      "3      0.746190    2.538100e-01\n",
      "4      0.999993    7.237987e-06\n",
      "..          ...             ...\n",
      "287    0.999786    2.136711e-04\n",
      "288    1.000000    7.749142e-08\n",
      "289    0.999998    2.332809e-06\n",
      "290    0.981221    1.877949e-02\n",
      "291    0.999810    1.902522e-04\n",
      "\n",
      "[292 rows x 2 columns]}}\n",
      "{'ngrams_3': {'fold_no': 4, 'f2_score': 0.3623188405797102, 'confusion_matrix': {'tn': 229, 'fp': 20, 'fn': 28, 'tp': 15}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.996192        0.003808\n",
      "1      0.999408        0.000592\n",
      "2      0.999981        0.000019\n",
      "3      0.013288        0.986712\n",
      "4      0.996774        0.003226\n",
      "..          ...             ...\n",
      "287    0.961070        0.038930\n",
      "288    0.998973        0.001027\n",
      "289    0.886132        0.113868\n",
      "290    0.960341        0.039659\n",
      "291    0.970715        0.029285\n",
      "\n",
      "[292 rows x 2 columns]}}\n",
      "{'ngrams_3': {'fold_no': 5, 'f2_score': 0.27522935779816515, 'confusion_matrix': {'tn': 215, 'fp': 34, 'fn': 31, 'tp': 12}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.927939        0.072061\n",
      "1      0.679213        0.320787\n",
      "2      0.063893        0.936107\n",
      "3      0.973510        0.026490\n",
      "4      0.950037        0.049963\n",
      "..          ...             ...\n",
      "287    0.961075        0.038925\n",
      "288    0.963494        0.036506\n",
      "289    0.998003        0.001997\n",
      "290    0.002479        0.997521\n",
      "291    0.984276        0.015724\n",
      "\n",
      "[292 rows x 2 columns]}}\n",
      "{'ngrams_4': {'fold_no': 1, 'f2_score': 0.3605769230769231, 'confusion_matrix': {'tn': 232, 'fp': 17, 'fn': 29, 'tp': 15}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.997259        0.002741\n",
      "1      0.856427        0.143573\n",
      "2      0.048071        0.951929\n",
      "3      0.995512        0.004488\n",
      "4      0.977316        0.022684\n",
      "..          ...             ...\n",
      "288    0.984527        0.015473\n",
      "289    0.994624        0.005376\n",
      "290    0.994867        0.005133\n",
      "291    0.950286        0.049714\n",
      "292    0.999445        0.000555\n",
      "\n",
      "[293 rows x 2 columns]}}\n",
      "{'ngrams_4': {'fold_no': 2, 'f2_score': 0.3066037735849057, 'confusion_matrix': {'tn': 225, 'fp': 23, 'fn': 31, 'tp': 13}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.985648        0.014352\n",
      "1      0.311811        0.688189\n",
      "2      0.308789        0.691211\n",
      "3      0.999921        0.000079\n",
      "4      0.970299        0.029701\n",
      "..          ...             ...\n",
      "287    0.027958        0.972042\n",
      "288    0.973052        0.026948\n",
      "289    0.911807        0.088193\n",
      "290    0.999990        0.000010\n",
      "291    0.999156        0.000844\n",
      "\n",
      "[292 rows x 2 columns]}}\n",
      "{'ngrams_4': {'fold_no': 3, 'f2_score': 0.24509803921568626, 'confusion_matrix': {'tn': 227, 'fp': 22, 'fn': 33, 'tp': 10}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.961812        0.038188\n",
      "1      0.181631        0.818369\n",
      "2      0.994086        0.005914\n",
      "3      0.207831        0.792169\n",
      "4      0.999991        0.000009\n",
      "..          ...             ...\n",
      "287    0.999016        0.000984\n",
      "288    0.999998        0.000002\n",
      "289    0.999968        0.000032\n",
      "290    0.999206        0.000794\n",
      "291    0.999896        0.000104\n",
      "\n",
      "[292 rows x 2 columns]}}\n",
      "{'ngrams_4': {'fold_no': 4, 'f2_score': 0.3744493392070484, 'confusion_matrix': {'tn': 211, 'fp': 38, 'fn': 26, 'tp': 17}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.863645        0.136355\n",
      "1      0.859521        0.140479\n",
      "2      0.999995        0.000005\n",
      "3      0.095607        0.904393\n",
      "4      0.952341        0.047659\n",
      "..          ...             ...\n",
      "287    0.031070        0.968930\n",
      "288    0.786197        0.213803\n",
      "289    0.051575        0.948425\n",
      "290    0.988023        0.011977\n",
      "291    0.975779        0.024221\n",
      "\n",
      "[292 rows x 2 columns]}}\n",
      "{'ngrams_4': {'fold_no': 5, 'f2_score': 0.31111111111111117, 'confusion_matrix': {'tn': 210, 'fp': 39, 'fn': 29, 'tp': 14}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.896008        0.103992\n",
      "1      0.663105        0.336895\n",
      "2      0.239393        0.760607\n",
      "3      0.746991        0.253009\n",
      "4      0.941990        0.058010\n",
      "..          ...             ...\n",
      "287    0.990760        0.009240\n",
      "288    0.854619        0.145381\n",
      "289    0.998970        0.001030\n",
      "290    0.160700        0.839300\n",
      "291    0.852895        0.147105\n",
      "\n",
      "[292 rows x 2 columns]}}\n",
      "{'ngrams_5': {'fold_no': 1, 'f2_score': 0.3282828282828283, 'confusion_matrix': {'tn': 240, 'fp': 9, 'fn': 31, 'tp': 13}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.988755        0.011245\n",
      "1      0.864559        0.135441\n",
      "2      0.313162        0.686838\n",
      "3      0.991220        0.008780\n",
      "4      0.949513        0.050487\n",
      "..          ...             ...\n",
      "288    0.879448        0.120552\n",
      "289    0.939813        0.060187\n",
      "290    0.972697        0.027303\n",
      "291    0.916267        0.083733\n",
      "292    0.988148        0.011852\n",
      "\n",
      "[293 rows x 2 columns]}}\n",
      "{'ngrams_5': {'fold_no': 2, 'f2_score': 0.21951219512195122, 'confusion_matrix': {'tn': 228, 'fp': 20, 'fn': 35, 'tp': 9}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.952519        0.047481\n",
      "1      0.179328        0.820672\n",
      "2      0.647511        0.352489\n",
      "3      0.999481        0.000519\n",
      "4      0.852010        0.147990\n",
      "..          ...             ...\n",
      "287    0.127153        0.872847\n",
      "288    0.959739        0.040261\n",
      "289    0.965537        0.034463\n",
      "290    0.999901        0.000099\n",
      "291    0.995679        0.004321\n",
      "\n",
      "[292 rows x 2 columns]}}\n",
      "{'ngrams_5': {'fold_no': 3, 'f2_score': 0.2682926829268293, 'confusion_matrix': {'tn': 227, 'fp': 22, 'fn': 32, 'tp': 11}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.851155        0.148845\n",
      "1      0.439095        0.560905\n",
      "2      0.986392        0.013608\n",
      "3      0.649934        0.350066\n",
      "4      0.999680        0.000320\n",
      "..          ...             ...\n",
      "287    0.995498        0.004502\n",
      "288    0.999871        0.000129\n",
      "289    0.998679        0.001321\n",
      "290    0.994872        0.005128\n",
      "291    0.996047        0.003953\n",
      "\n",
      "[292 rows x 2 columns]}}\n",
      "{'ngrams_5': {'fold_no': 4, 'f2_score': 0.34403669724770647, 'confusion_matrix': {'tn': 218, 'fp': 31, 'fn': 28, 'tp': 15}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.619181        0.380819\n",
      "1      0.925240        0.074760\n",
      "2      0.999946        0.000054\n",
      "3      0.181954        0.818046\n",
      "4      0.851155        0.148845\n",
      "..          ...             ...\n",
      "287    0.003425        0.996575\n",
      "288    0.141004        0.858996\n",
      "289    0.010515        0.989485\n",
      "290    0.985664        0.014336\n",
      "291    0.945022        0.054978\n",
      "\n",
      "[292 rows x 2 columns]}}\n",
      "{'ngrams_5': {'fold_no': 5, 'f2_score': 0.2898550724637681, 'confusion_matrix': {'tn': 226, 'fp': 23, 'fn': 31, 'tp': 12}, 'predicted_probabilities':      irish_prob  not_irish_prob\n",
      "0      0.395067        0.604933\n",
      "1      0.794096        0.205904\n",
      "2      0.548461        0.451539\n",
      "3      0.822823        0.177177\n",
      "4      0.853052        0.146948\n",
      "..          ...             ...\n",
      "287    0.980608        0.019392\n",
      "288    0.851155        0.148845\n",
      "289    0.995846        0.004154\n",
      "290    0.851155        0.148845\n",
      "291    0.851155        0.148845\n",
      "\n",
      "[292 rows x 2 columns]}}\n"
     ]
    }
   ],
   "source": [
    "n_length = [3,4,5]\n",
    "\n",
    "all_model_results = {}\n",
    "\n",
    "for n in n_length:\n",
    "    ngrams = ngram_creator(df['name'], n)\n",
    "    df_grams = pd.DataFrame(zip(ngrams,df['irish_flag']), columns=['ngrams','irish_flag'])\n",
    "\n",
    "    # print(ngrams)\n",
    "    # print(df_grams['ngrams'])\n",
    "    # break\n",
    "\n",
    "    target = df_grams.loc[:,'irish_flag']\n",
    "\n",
    "    model_results = summarize_model(df_grams, target, model_type=n)\n",
    "\n",
    "    all_model_results[f'{n}_grams'] = model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be754d456665c43c25f900212453ea73e5099fd72606cb8c80f2e995c5f22720"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
